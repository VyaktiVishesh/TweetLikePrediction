{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8056593,
          "sourceType": "datasetVersion",
          "datasetId": 4751853
        },
        {
          "sourceId": 8056875,
          "sourceType": "datasetVersion",
          "datasetId": 4752053
        },
        {
          "sourceId": 8056926,
          "sourceType": "datasetVersion",
          "datasetId": 4752091
        },
        {
          "sourceId": 8056957,
          "sourceType": "datasetVersion",
          "datasetId": 4752114
        }
      ],
      "dockerImageVersionId": 30684,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import csv\n",
        "import re"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-04-10T06:32:14.904690Z",
          "iopub.execute_input": "2024-04-10T06:32:14.905988Z",
          "iopub.status.idle": "2024-04-10T06:32:16.221312Z",
          "shell.execute_reply.started": "2024-04-10T06:32:14.905949Z",
          "shell.execute_reply": "2024-04-10T06:32:16.220427Z"
        },
        "trusted": true,
        "id": "oYGAYLsrWVjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing noise from the tweet data like non-alphanumeric and hashes"
      ],
      "metadata": {
        "id": "mo_wqdJZWVjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def contains_https_link(tweet):\n",
        "    return bool(re.search(r'https://', tweet))\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "    all_text  = re.sub(\"#\\S*\\s\", \"\", tweet)\n",
        "    all_text  = re.sub(\"W+\", \"\", all_text)\n",
        "    all_text  = re.sub(\"@\\S*\\s\", \"\", all_text)\n",
        "    all_text = re.sub(r'https?://\\S+', '', all_text)\n",
        "    all_text = re.sub(r'[^\\x00-\\x7F]+', '', all_text)\n",
        "    return all_text\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "def standard_time(timeST):\n",
        "    timestamp = datetime.strptime(timeST, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
        "    hour = timestamp.hour\n",
        "    minute = timestamp.minute\n",
        "    second = timestamp.second\n",
        "    time_numeric = (hour * 3600) + (minute * 60) + second\n",
        "    return time_numeric\n",
        "\n",
        "def like_to_label(likes):\n",
        "    if likes >= 10000:\n",
        "        return 4\n",
        "    if likes >= 1000:\n",
        "        return 3\n",
        "    if likes >= 100:\n",
        "        return 2\n",
        "    if likes >= 10:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T06:32:19.561188Z",
          "iopub.execute_input": "2024-04-10T06:32:19.561787Z",
          "iopub.status.idle": "2024-04-10T06:32:19.573974Z",
          "shell.execute_reply.started": "2024-04-10T06:32:19.561749Z",
          "shell.execute_reply": "2024-04-10T06:32:19.572673Z"
        },
        "trusted": true,
        "id": "SeLwm4wYWVjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Data From File"
      ],
      "metadata": {
        "id": "0SoAYEQeWVjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('../Datasets/tweet_data3.csv')\n",
        "print(df.columns)\n",
        "\n",
        "# Clean the tweet column\n",
        "df['embedded_video'] = df['Tweet Text'].apply(contains_https_link)\n",
        "df['cleaned_tweet'] = df['Tweet Text'].apply(clean_tweet)\n",
        "df['converted_time'] = df['Time of Tweet'].apply(standard_time)\n",
        "df['label'] = df['Like Count'].apply(like_to_label)\n",
        "\n",
        "# Save the cleaned data to a new CSV file\n",
        "# df.to_csv('cleaned_dataset.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T06:32:24.275339Z",
          "iopub.execute_input": "2024-04-10T06:32:24.276187Z",
          "iopub.status.idle": "2024-04-10T06:32:25.141702Z",
          "shell.execute_reply.started": "2024-04-10T06:32:24.276136Z",
          "shell.execute_reply": "2024-04-10T06:32:25.140265Z"
        },
        "trusted": true,
        "id": "Tq_tMBpVWVjs",
        "outputId": "8954b249-0dce-4b79-d4f6-d076a7e07b8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Index(['Tweet Text', 'Like Count', 'Followers Count', 'Time of Tweet'], dtype='object')\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Stop Words"
      ],
      "metadata": {
        "id": "c8FUTSPgWVjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import nltk\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stopwords1 = stopwords.words('english')\n",
        "\n",
        "en = spacy.load(\"en_core_web_lg\")\n",
        "stopwords2 = en.Defaults.stop_words\n",
        "\n",
        "stop_words = stopwords1 + list(stopwords2)\n",
        "print(stop_words)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T06:32:27.932956Z",
          "iopub.execute_input": "2024-04-10T06:32:27.934146Z",
          "iopub.status.idle": "2024-04-10T06:32:42.347616Z",
          "shell.execute_reply.started": "2024-04-10T06:32:27.934105Z",
          "shell.execute_reply": "2024-04-10T06:32:42.346280Z"
        },
        "trusted": true,
        "id": "3mGpG4vVWVjt",
        "outputId": "3cdacde6-5d40-44b1-d3c9-ced6fee6e8e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'where', 'less', 'a', 'per', 'not', 'back', 'last', 'often', 'whether', 'but', 'in', 'doing', 'anyone', 'keep', 'thus', 'former', 'toward', 'that', 'give', 'bottom', 'am', 'hereby', 'became', 'whatever', 'each', 'others', 'they', 'an', 'onto', 'cannot', 'which', 'also', 'myself', 'serious', 'their', 'mine', \"'d\", \"n't\", 'go', 'can', 'our', 'front', 'mostly', 'either', 'over', 'do', 'several', 'other', 'through', 'wherever', 'could', 'itself', 'more', 'enough', 'hereupon', 'whereby', 'five', 'now', 'whereafter', 'put', 'please', 'any', 'least', 'its', 'ourselves', 'someone', 'something', 'together', 'six', 'off', 'has', 'both', 'this', '‘ll', 'therefore', 'above', 'eight', 'every', 'side', 'them', 'meanwhile', 'against', 'nowhere', 'becoming', 'really', 'behind', 'him', 'further', 'into', 'until', 'third', 'nine', 'otherwise', 'moreover', 'one', 'made', 'to', 'make', \"'ll\", 'who', 'themselves', 'whenever', 'you', 'does', 'perhaps', '’ll', 'when', 'whence', '’ve', 'rather', 'hence', 'alone', 'yourselves', 'at', 'being', 'well', 'due', 'indeed', 'never', 'me', 'for', 'even', 'thence', '‘d', 'seemed', 'n’t', 'whoever', 'whose', 'himself', 'among', 'empty', 'forty', 'about', 'have', 'ours', 'as', 'down', 'anywhere', 'whom', 'formerly', 'regarding', 'up', 'two', 'hereafter', 'had', 'seeming', 'might', 'it', 'somewhere', 'see', 'these', 'must', 'ten', 'be', 'amongst', '’d', 'whereupon', 'across', 'before', 'because', 'once', '‘s', 'via', 'us', 'become', 'nobody', 'amount', 'fifty', 'next', 'while', '‘ve', 'except', 'four', 'she', 'many', 'and', 'after', 'on', 'between', 'under', 'thereby', 'almost', 'get', 'the', 'anyhow', 'first', 'your', 'all', 'below', 'whereas', 'still', 'is', 'besides', 'by', 'again', 'thru', 'there', 'fifteen', 'here', 'say', 'nevertheless', 'i', 'ever', 'or', 'would', 'beside', 'everything', 'noone', \"'re\", 'his', 'herself', 'wherein', 'how', 'n‘t', 'few', 'whole', '‘re', 'should', 'most', 'name', 'using', 'own', \"'m\", 'done', 'yet', 'somehow', 'however', 'call', 'quite', 'towards', 'herein', 're', 'are', 'else', 'will', 'sometimes', 'beyond', 'were', 'may', 'therein', '’s', 'seem', 'he', 'various', '’re', 'top', 'everywhere', 'seems', 'upon', 'out', 'of', 'what', \"'ve\", 'move', 'only', '‘m', 'already', 'beforehand', 'latterly', 'some', 'from', 'during', 'such', 'another', 'becomes', 'so', 'with', 'take', 'within', 'full', 'namely', 'latter', 'if', 'twenty', 'nor', 'always', 'part', 'her', 'much', 'same', 'around', 'than', 'been', 'throughout', 'we', '’m', 'no', 'unless', 'yourself', 'just', 'along', 'sixty', 'twelve', 'show', 'neither', 'hundred', 'very', 'without', 'three', 'too', 'my', 'hers', \"'s\", 'since', 'why', 'elsewhere', 'then', 'anything', 'yours', 'thereupon', 'ca', 'those', 'used', 'everyone', 'whither', 'thereafter', 'anyway', 'afterwards', 'eleven', 'none', 'although', 'though', 'sometime', 'nothing', 'was', 'did']\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Keywords Using RAKE Algo"
      ],
      "metadata": {
        "id": "PtFHad43WVjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters, punctuation, and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "def calculate_word_scores(sentences):\n",
        "    word_freq = Counter()\n",
        "    word_degree = Counter()\n",
        "    for sentence in sentences:\n",
        "        word_list = re.findall(r'\\w+', sentence)\n",
        "        word_list = [word for word in word_list if len(word) > 1]  # Filter out single-character words\n",
        "        word_freq.update(word_list)\n",
        "        for word in word_list:\n",
        "            word_degree[word] += len(word_list) - 1  # Increment the degree by the count of other words in the sentence\n",
        "\n",
        "    word_scores = Counter()\n",
        "    for word in word_freq:\n",
        "        word_scores[word] = word_degree[word] / word_freq[word]\n",
        "    return word_scores\n",
        "\n",
        "def calculate_phrase_scores(sentences, word_scores):\n",
        "    phrase_scores = Counter()\n",
        "    for sentence in sentences:\n",
        "        phrase_list = re.findall(r'\\w+', sentence)\n",
        "        phrase_list = [phrase for phrase in phrase_list if len(phrase) > 1]  # Filter out single-word phrases\n",
        "        phrase_score = sum(word_scores[word] for word in phrase_list)\n",
        "        phrase_scores[' '.join(phrase_list)] = phrase_score\n",
        "    return phrase_scores\n",
        "\n",
        "def extract_keywords(text, num_keywords=5):\n",
        "    split_pattern = r'[.!?]|(?:\\s|^)(?:{})\\b'.format('|'.join(map(re.escape, stop_words)))\n",
        "    text = preprocess_text(text)\n",
        "    sentences = re.split(split_pattern, text)\n",
        "    sentences = [sentence for sentence in sentences if sentence.strip()]\n",
        "    word_scores = calculate_word_scores(sentences)\n",
        "    phrase_scores = calculate_phrase_scores(sentences, word_scores)\n",
        "    keywords = phrase_scores.most_common(num_keywords)\n",
        "    most_words = word_scores.most_common(num_keywords)\n",
        "    return keywords, most_words\n",
        "\n",
        "text = \"BOMBSHELL Proof COVID Antiviral Pill Molnupirivar By Merck Causes SARS-CoV-2 Mutations\"\n",
        "keywords, words = extract_keywords(text)\n",
        "print(\"Top keywords:\", keywords)\n",
        "print(\"Top Words: \", words)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T06:32:48.614801Z",
          "iopub.execute_input": "2024-04-10T06:32:48.615497Z",
          "iopub.status.idle": "2024-04-10T06:32:48.648481Z",
          "shell.execute_reply.started": "2024-04-10T06:32:48.615461Z",
          "shell.execute_reply": "2024-04-10T06:32:48.647419Z"
        },
        "trusted": true,
        "id": "qT53biAiWVjt",
        "outputId": "63a8edef-d0eb-44da-c7a2-7b30b5f70e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Top keywords: [('bombshell proof covid antiviral pill molnupirivar', 30.0), ('merck causes sarscov mutations', 12.0)]\nTop Words:  [('bombshell', 5.0), ('proof', 5.0), ('covid', 5.0), ('antiviral', 5.0), ('pill', 5.0)]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting Top Keywords to Tokens"
      ],
      "metadata": {
        "id": "hn2KgixaWVjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def keyword_to_embeddings(top_keywords):\n",
        "    word_embeddings = []\n",
        "    for keyword in top_keywords:\n",
        "        token = en(keyword[0])\n",
        "        if token.has_vector:\n",
        "            word_embeddings.append(token.vector)\n",
        "        else:\n",
        "            word_embeddings.append(np.zeros(300))\n",
        "\n",
        "    while len(word_embeddings) < 5:\n",
        "        word_embeddings.append(np.zeros(300))\n",
        "\n",
        "    return word_embeddings\n",
        "\n",
        "#print(keyword_to_embeddings([('bombshell', 5.0), ('proof', 5.0), ('covid', 5.0)]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T06:32:53.074314Z",
          "iopub.execute_input": "2024-04-10T06:32:53.074749Z",
          "iopub.status.idle": "2024-04-10T06:32:53.081880Z",
          "shell.execute_reply.started": "2024-04-10T06:32:53.074703Z",
          "shell.execute_reply": "2024-04-10T06:32:53.080594Z"
        },
        "trusted": true,
        "id": "akBllw4IWVju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_embeddings = []\n",
        "count = 0\n",
        "for tweet in df['cleaned_tweet']:\n",
        "    _,tweet_top_keywords = extract_keywords(tweet)\n",
        "    embeddings = keyword_to_embeddings(tweet_top_keywords)\n",
        "    keyword_embeddings.append(embeddings)\n",
        "    count += 1\n",
        "    if(count%1000 == 0):\n",
        "        print(count)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T06:32:59.109758Z",
          "iopub.execute_input": "2024-04-10T06:32:59.110901Z",
          "iopub.status.idle": "2024-04-10T06:42:14.863863Z",
          "shell.execute_reply.started": "2024-04-10T06:32:59.110862Z",
          "shell.execute_reply": "2024-04-10T06:42:14.862552Z"
        },
        "trusted": true,
        "id": "JNjnZPd4WVju",
        "outputId": "901e06b3-01ff-4658-87ff-3f1290c3e641"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n11000\n12000\n13000\n14000\n15000\n16000\n17000\n18000\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(keyword_embeddings[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T06:42:47.481982Z",
          "iopub.execute_input": "2024-04-10T06:42:47.483172Z",
          "iopub.status.idle": "2024-04-10T06:42:47.505002Z",
          "shell.execute_reply.started": "2024-04-10T06:42:47.483120Z",
          "shell.execute_reply": "2024-04-10T06:42:47.503784Z"
        },
        "trusted": true,
        "id": "ovKNo0aEWVju",
        "outputId": "2a6366a1-6e00-4d28-92a4-5e23a0d0fc75"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[array([-1.2047e+00, -1.8841e+00, -4.1402e+00, -3.0751e+00,  1.8830e+00,\n       -1.8872e+00,  2.5263e-01,  5.3627e+00, -1.7144e+00, -1.5174e+00,\n        7.1173e+00,  1.1453e+00, -3.9868e+00, -8.1233e-01,  1.7725e+00,\n        8.0080e-01,  1.1651e+00, -1.9638e+00, -1.6211e+00,  1.8036e+00,\n       -1.4354e+00,  1.3000e+00,  8.8791e-01, -1.8825e+00,  4.1976e-01,\n        8.8296e-01,  7.6003e-01, -4.9952e-01,  5.6729e-01,  4.0458e-01,\n        3.6411e+00, -4.8239e+00, -4.1680e-01, -4.6972e+00,  2.0365e+00,\n        1.0195e+00,  1.9232e+00,  1.2530e+00,  5.9611e-01,  9.5434e-01,\n       -4.4911e+00, -1.6139e-01, -2.4083e+00, -1.2584e+00, -2.8906e+00,\n        2.5896e+00,  2.8413e+00, -3.4578e+00, -1.7886e+00,  5.0010e+00,\n        2.6081e+00,  5.1367e+00, -2.5518e+00, -3.3774e+00,  3.2658e-01,\n        2.2195e+00,  2.4562e+00,  2.5930e+00,  9.9261e-01,  1.3204e+00,\n        3.6505e-01, -5.6079e-03,  3.2209e+00, -2.6231e+00,  4.4062e+00,\n        1.8690e+00, -5.4214e+00, -4.1069e+00, -3.8010e-01,  7.8807e-01,\n        2.9699e+00, -2.3184e+00, -1.9630e+00,  2.9344e-01, -2.5543e+00,\n        1.2524e+00, -1.9424e+00,  1.1581e+00,  5.1247e-01, -4.3601e-02,\n       -6.0333e+00, -2.1214e+00, -9.5811e-01,  5.2398e+00,  4.2619e+00,\n        1.3237e+00, -1.4895e-01, -4.4143e+00, -2.3375e+00,  1.4569e+00,\n        2.9202e-01,  2.0103e+00,  1.8370e+00, -1.0423e+00, -5.5970e-01,\n       -3.4224e+00, -4.6864e+00, -3.8000e+00, -3.6736e-01,  1.9378e+00,\n        4.1262e+00,  4.3207e+00,  5.6837e+00,  5.9543e+00, -3.9371e-01,\n        3.5298e+00, -2.8732e+00, -3.4284e+00, -3.4582e+00, -4.0600e+00,\n        3.3017e+00,  4.8110e-01, -1.5593e+00, -2.6921e+00, -1.3480e+00,\n        2.1792e+00,  1.5514e+00, -1.2951e+00, -7.3729e-01,  7.1328e-01,\n       -2.4885e+00, -4.8924e+00,  5.9502e-01,  6.0771e-01,  1.1840e-02,\n       -3.0849e+00,  1.9025e+00, -1.3017e+00,  2.9488e+00, -3.1900e-01,\n       -1.2693e+00,  3.1220e+00,  4.0060e+00, -1.2068e+00, -4.8492e-02,\n        6.4846e-01, -5.2481e+00, -2.6626e+00,  5.3626e+00, -3.2961e+00,\n       -3.7358e-01,  2.4319e+00, -9.2440e-01,  2.0785e+00, -1.1744e+00,\n        3.5956e-01, -5.8070e+00, -2.0124e+00,  2.4207e+00,  6.2887e+00,\n       -5.4986e-01,  2.5072e+00,  2.2101e+00,  4.7830e+00, -1.8390e+00,\n        4.1141e+00,  2.6769e+00,  1.8826e-01,  6.1603e-01, -2.8647e+00,\n        2.4280e+00, -5.6279e-01,  1.5897e+00, -4.0553e-01,  9.5368e-02,\n        8.0547e-01,  3.4701e-02, -2.6220e+00,  6.3523e-01,  7.5307e-01,\n        2.3586e+00,  1.6974e+00,  2.4255e+00, -1.5628e+00,  8.0760e-01,\n        1.1835e+00,  2.3820e-01,  2.2864e+00, -4.9857e-01, -1.9400e+00,\n       -6.7259e-01, -1.6260e+00,  8.7967e+00, -2.6547e-01, -3.8602e+00,\n        8.0884e-02, -9.6321e-01,  4.0740e-01, -3.1163e-01,  2.7002e+00,\n        8.9022e-01,  3.4280e-01, -6.1905e+00, -1.4472e+00, -1.8813e+00,\n       -4.6551e+00, -5.1669e+00, -2.7315e+00,  7.4882e-01, -2.5178e+00,\n        2.7138e-01, -3.7064e-01, -1.5716e-01, -3.6197e+00, -1.8057e+00,\n       -7.3599e-01, -6.7271e+00,  2.3927e+00,  3.6462e+00,  1.4632e+00,\n       -1.8605e+00,  2.0543e+00, -1.6299e+00,  1.7978e+00, -1.0810e+00,\n        2.3885e-01, -2.9224e-01, -1.0949e+00, -2.3132e+00,  5.3490e-01,\n       -4.3905e-01,  1.1234e+00,  3.6313e+00, -2.0432e+00,  1.1087e+00,\n        1.8822e+00,  2.0181e+00,  4.4418e+00,  1.0858e+00,  9.7456e-01,\n       -2.9504e-01, -2.4936e+00, -2.3516e+00,  3.8258e+00, -2.6150e+00,\n        4.6984e+00, -2.5047e+00,  3.5631e+00, -3.0970e+00, -4.8310e-01,\n       -3.6326e+00, -1.5897e+00,  1.9552e+00,  5.9357e-01,  1.2812e+00,\n       -1.1391e+00, -5.8058e+00, -3.6656e+00, -3.1598e-01, -1.5304e+00,\n        1.8341e+00, -1.1101e+00, -3.1611e+00,  8.9298e-01, -2.0754e+00,\n       -4.0649e+00,  5.0264e+00, -1.0379e+00, -1.0605e+00,  2.7143e+00,\n       -2.0780e+00,  3.4617e+00, -8.3981e-01,  1.6505e+00,  2.7111e+00,\n        1.0843e+00, -1.9535e+00, -4.1174e-01, -1.0734e+00, -2.8323e-01,\n        6.7581e-01, -1.3433e+00,  1.1284e+00, -2.7050e+00, -2.5329e+00,\n        1.7635e+00,  1.7623e+00,  4.2555e-01,  3.6866e+00,  1.9793e+00,\n        5.9986e-02,  5.2904e-01, -2.8901e+00, -2.0970e-01,  2.0589e-01,\n        1.9648e+00, -4.7510e-01,  1.9747e+00, -4.7604e+00, -2.5503e+00,\n       -8.4162e-01,  2.7350e+00, -2.5145e+00, -2.7564e+00,  5.4722e+00,\n       -7.0782e-01, -4.2719e+00, -1.6814e+00, -3.0689e+00,  8.3428e-01],\n      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the list of embeddings into a NumPy array\n",
        "keyword_embeddings_array = np.array(keyword_embeddings)\n",
        "print(keyword_embeddings_array[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T06:42:56.709738Z",
          "iopub.execute_input": "2024-04-10T06:42:56.710796Z",
          "iopub.status.idle": "2024-04-10T06:42:56.912772Z",
          "shell.execute_reply.started": "2024-04-10T06:42:56.710743Z",
          "shell.execute_reply": "2024-04-10T06:42:56.911312Z"
        },
        "trusted": true,
        "id": "4oGqxRSyWVju",
        "outputId": "f51c01d5-d548-4c50-efb0-2933a6140693"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[[-1.20469999 -1.88409996 -4.14020014 ... -1.68139994 -3.06890011\n   0.83428001]\n [ 0.          0.          0.         ...  0.          0.\n   0.        ]\n [ 0.          0.          0.         ...  0.          0.\n   0.        ]\n [ 0.          0.          0.         ...  0.          0.\n   0.        ]\n [ 0.          0.          0.         ...  0.          0.\n   0.        ]]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Splitting"
      ],
      "metadata": {
        "id": "VfGg0nrpWVjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_time = df['converted_time'].values.reshape(-1, 1)\n",
        "X_followers = df['Followers Count'].values.reshape(-1,1)\n",
        "X_video_flag = df['embedded_video'].values.reshape(-1,1)\n",
        "X_text = keyword_embeddings_array.reshape(18050,1500)\n",
        "# print(X_text.shape)\n",
        "# print(X_text[0])\n",
        "X = np.hstack((X_time, X_followers, X_video_flag, X_text))\n",
        "# X = df[['cleaned_tweet', 'Followers Count', 'converted_time']]\n",
        "v = np.array(df['label'])\n",
        "y = []\n",
        "for i in v:\n",
        "    y.append([0, 0, 0, 0, 0])\n",
        "    y[-1][i] = 1\n",
        "y = np.array(y)\n",
        "print(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(X_train[99])\n",
        "print(y_train[99])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T06:43:03.020964Z",
          "iopub.execute_input": "2024-04-10T06:43:03.021391Z",
          "iopub.status.idle": "2024-04-10T06:43:03.303143Z",
          "shell.execute_reply.started": "2024-04-10T06:43:03.021357Z",
          "shell.execute_reply": "2024-04-10T06:43:03.302133Z"
        },
        "trusted": true,
        "id": "IkaUisj8WVjv",
        "outputId": "26f56bc2-1e44-49a5-c758-a0229c231aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[[1 0 0 0 0]\n [1 0 0 0 0]\n [0 0 0 1 0]\n ...\n [0 0 1 0 0]\n [0 0 1 0 0]\n [0 0 1 0 0]]\n[ 51867. 340824.      0. ...      0.      0.      0.]\n[0 0 0 1 0]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "ipAJyTaiWVjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Assuming you have multi-class labels\n",
        "num_classes = 5  # Number of classes in your dataset\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=1503, activation='relu'))  # Input layer with 1503 dimensions\n",
        "model.add(Dense(32, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(num_classes, activation='softmax'))  # Output layer for multi-class classification\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=12000, batch_size=8, validation_split=0.2, verbose=0)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "loss, accuracy, precision = model.evaluate(X_test, y_test)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Precision\", precision)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T07:39:34.893674Z",
          "iopub.execute_input": "2024-04-10T07:39:34.894089Z",
          "iopub.status.idle": "2024-04-10T07:39:34.905547Z",
          "shell.execute_reply.started": "2024-04-10T07:39:34.894061Z",
          "shell.execute_reply": "2024-04-10T07:39:34.904317Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDquTr1oWVjv",
        "outputId": "963d607c-d54b-4215-a5d4-c3b09ed394fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\u001b[92m ━━━━━━━━━━━━━━━━━━━━\u001b[0m 5s 4s/step - accuracy: 0.0286 - loss: 6189.642\n",
            "\n",
            "Epoch 2/10\u001b[92m ━━━━━━━━━━━━━━━━━━━━\u001b[0m 5s 4s/step - accuracy: 0.2654 - loss: 178.401\n",
            "\n",
            "Epoch 3/10\u001b[92m ━━━━━━━━━━━━━━━━━━━━\u001b[0m 3s 4s/step - accuracy: 0.3427 - loss: 15.3853\n",
            "\n",
            "Epoch 4/10\u001b[92m ━━━━━━━━━━━━━━━━━━━━\u001b[0m 3s 4s/step - accuracy: 0.3744 - loss: 13.9610\n",
            "\n",
            "Epoch 5/10\u001b[92m ━━━━━━━━━━━━━━━━━━━━\u001b[0m 3s 4s/step - accuracy: 0.4753 - loss: 13.6031\n",
            "\n",
            "Epoch 6/10\u001b[92m ━━━━━━━━━━━━━━━━━━━━\u001b[0m 3s 4s/step - accuracy: 0.5362 - loss: 9.2451\n",
            "\n",
            "Epoch 7/10\u001b[92m ━━━━━━━━━━━━━━━━━━━━\u001b[0m 3s 4s/step - accuracy: 0.6387 - loss: 6.5475\n",
            "\n",
            "Epoch 8/10\u001b[92m ━━━━━━━━━━━━━━━━━━━━\u001b[0m 3s 4s/step - accuracy: 0.6548 - loss: 3.4587\n",
            "\n",
            "Epoch 9/10\u001b[92m ━━━━━━━━━━━━━━━━━━━━\u001b[0m 3s 4s/step - accuracy: 0.7406 - loss: 2.6970\n",
            "\n",
            "Epoch 10/10\u001b[92m ━━━━━━━━━━━━━━━━━━━━\u001b[0m 3s 4s/step - accuracy: 0.7102 - loss: 0.6011\n",
            "\n",
            "Accuracy: 0.7102\n",
            "Loss: 0.6011\n",
            "Precision: 0.604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jhj7uHPgWVjv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}